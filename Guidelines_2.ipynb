{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjcAdLh/dbE/zsJNibwcTj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keyom-ai/prompts/blob/main/Guidelines_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Guidelines for Prompting**\n",
        "\n",
        "In this lesson, you'll practice two prompting principles and their related tactics in order to write effective prompts for large language models.\n",
        "\n",
        "Setup\n",
        "Load the API key and relevant Python libaries."
      ],
      "metadata": {
        "id": "98_B0EWRS8-p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQrGIQrfSrZq",
        "outputId": "1b2a5460-e5f6-42ac-f488-b0e32876e155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.27\n",
            "  Downloading openai-0.27.0-py3-none-any.whl (70 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.27) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.27) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.27.0\n"
          ]
        }
      ],
      "source": [
        "pip install openai==0.27"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the below cell, please insert your own API keys as value for openai.api_key variable. You can create your own API keys at (https://platform.openai.com/api-keys)"
      ],
      "metadata": {
        "id": "-fP7iC-oT4MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = 'sk-abcdefghijklmnopqrstuvwxyz0123456789'"
      ],
      "metadata": {
        "id": "E_uAX6JYTgX2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper function**\n",
        "\n",
        "Throughout this course, we will use OpenAI's gpt-3.5-turbo model and the [chat completions endpoint.](https://platform.openai.com/docs/guides/text-generation/chat-completions-api)\n",
        "\n",
        "This helper function will make it easier to use prompts and look at the generated outputs."
      ],
      "metadata": {
        "id": "LC1Jj3l_7zZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']"
      ],
      "metadata": {
        "id": "KpXcTRxv-_fL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompting Principles**\n",
        "\n",
        "Principle 1: Write clear and specific instructions\n",
        "\n",
        "Principle 2: Give the model time to “think”\n",
        "\n",
        "**Tactics**\n",
        "\n",
        "Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
        "\n",
        "Delimiters can be anything like: ```, \"\"\", < >, , :"
      ],
      "metadata": {
        "id": "nEGyd5yXYCUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "You should express what you want a model to do by\n",
        "providing instructions that are as clear and\n",
        "specific as you can possibly make them.\n",
        "This will guide the model towards the desired output,\n",
        "and reduce the chances of receiving irrelevant\n",
        "or incorrect responses. Don't confuse writing a\n",
        "clear prompt with writing a short prompt.\n",
        "In many cases, longer prompts provide more clarity\n",
        "and context for the model, which can lead to\n",
        "more detailed and relevant outputs.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by triple backticks\n",
        "into a single sentence.\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "response_content = get_completion(prompt)\n",
        "print(response_content)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hLHKXcwUSmB",
        "outputId": "904d2445-4fb5-48b2-9721-56ff80472aae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To guide a model towards the desired output and avoid irrelevant or incorrect responses, it is important to provide clear and specific instructions, even if they are longer, as they offer more clarity and context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tactic 2: Ask for a structured output\n",
        "\n",
        "1.   JSON, HTML\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ISaDe4Vd8bUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Generate a list of three made-up Song titles along \\\n",
        "with their artist and genres.\n",
        "Provide them in JSON format with the following keys:\n",
        "Song_id, title, artist, genre.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "vTcM4xgHYygh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4826b2a3-736b-4e85-9b34-3f21b3a6b23e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"songs\": [\n",
            "    {\n",
            "      \"song_id\": 1,\n",
            "      \"title\": \"Midnight Whispers\",\n",
            "      \"artist\": \"Luna Shadows\",\n",
            "      \"genre\": \"Indie Pop\"\n",
            "    },\n",
            "    {\n",
            "      \"song_id\": 2,\n",
            "      \"title\": \"Electric Dreams\",\n",
            "      \"artist\": \"Neon Skyline\",\n",
            "      \"genre\": \"Synthwave\"\n",
            "    },\n",
            "    {\n",
            "      \"song_id\": 3,\n",
            "      \"title\": \"Lost in the Cosmos\",\n",
            "      \"artist\": \"Stellar Voyager\",\n",
            "      \"genre\": \"Space Rock\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tactic 3: Ask the model to check whether conditions are satisfied"
      ],
      "metadata": {
        "id": "NL6LIGGy9R_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = f\"\"\"\n",
        "Making Ramen is easy! First, you need to get some\n",
        "water boiling. While that's happening,\n",
        "grab the ramen cake and put it in Once the water is\n",
        "hot enough\n",
        "Let it sit for a bit so the cake disintegrats into noodles . After a\n",
        "few minutes, drain the water and season the noodles\n",
        "with the seasoning mixture given in the package\n",
        "And that's it! You've got yourself a delicious\n",
        "bowl of ramen.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, \\\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions, \\\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Completion for Text 1:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7kR4LsR83Lz",
        "outputId": "2175937f-0db6-4a5c-e20b-affec78e91d7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 1:\n",
            "Step 1 - Get some water boiling.\n",
            "Step 2 - Grab the ramen cake and put it in the boiling water.\n",
            "Step 3 - Let it sit for a bit so the cake disintegrates into noodles.\n",
            "Step 4 - After a few minutes, drain the water.\n",
            "Step 5 - Season the noodles with the seasoning mixture given in the package.\n",
            "Step 6 - Enjoy your delicious bowl of ramen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = f\"\"\"\n",
        "The sky is clear and bright today and the birds are\n",
        "chipping. It's a pleasant day to go for a\n",
        "walk in the park. The flowers are blooming, and the\n",
        "trees are swaying gently in the breeze. People\n",
        "are out and about, enjoying the lovely weather.\n",
        "Some are having picnics, while others are playing\n",
        "games or simply relaxing on the grass. It's a\n",
        "perfect day to spend time outdoors and appreciate the\n",
        "beauty of nature.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, \\\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions, \\\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Completion for Text 2:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Xg2gDPvATRh",
        "outputId": "108aa2a1-9831-4de8-b8c3-77d57c23aab8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 2:\n",
            "No steps provided.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tactic 4: \"Few-shot\" prompting"
      ],
      "metadata": {
        "id": "PIhwTp_aBzsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to answer in a consistent style.\n",
        "\n",
        "<child>: Teach me about patience.\n",
        "\n",
        "<grandparent>: The river that carves the deepest\n",
        "valley flows from a modest spring; the\n",
        "grandest symphony originates from a single note;\n",
        "the most intricate tapestry begins with a solitary thread.\n",
        "\n",
        "<child>: Teach me about Knowledge.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYROurvzBug7",
        "outputId": "3ac4e640-c772-4c4e-a855-6e933a354c72"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<grandparent>: Knowledge is a vast ocean, ever expanding and boundless. It is the accumulation of wisdom, facts, and understanding that enriches our minds and empowers us. Just as a single drop of water contributes to the vastness of the ocean, every piece of knowledge we acquire adds to the depth and breadth of our understanding. Embrace the pursuit of knowledge, for it is a lifelong journey that opens doors to new possibilities and fuels personal growth.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Principle 2: Give the model time to “think”\n",
        "\n",
        "Tactic 1: Specify the steps required to complete a task"
      ],
      "metadata": {
        "id": "aMT6jfG1CY8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "A lion was once sleeping in the jungle when a mouse started running up and down his body just for fun.\n",
        "This disturbed the lion’s sleep, and he woke up quite angry.\n",
        "He was about to eat the mouse when the mouse desperately requested the lion to set him free.\n",
        "“I promise you, I will be of great help to you someday if you save me.” The lion laughed at the mouse’s confidence and let him go.\n",
        "\n",
        "One day, a few hunters came into the forest and took the lion with them.\n",
        "They tied him up against a tree. The lion was struggling to get out and started to whimper.\n",
        "Soon, the mouse walked past and noticed the lion in trouble.\n",
        "Quickly, he ran and gnawed on the ropes to set the lion free.\n",
        "Both of them sped off into the jungle.\n",
        "\"\"\"\n",
        "# example 1\n",
        "prompt_1 = f\"\"\"\n",
        "Perform the following actions:\n",
        "1 - Summarize the following text delimited by triple \\\n",
        "backticks with 1 sentence.\n",
        "2 - Translate the summary into French.\n",
        "3 - List each name in the French summary.\n",
        "4 - Output a json object that contains the following \\\n",
        "keys: french_summary, num_names.\n",
        "\n",
        "Separate your answers with line breaks.\n",
        "\n",
        "Text:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt_1)\n",
        "print(\"Completion for prompt 1:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xViowElfCG2x",
        "outputId": "d834e511-a00e-4a12-a20d-53a843d7ab02"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for prompt 1:\n",
            "1 - A lion is saved by a mouse and later returns the favor when the lion is captured by hunters.\n",
            "2 - Un lion est sauvé par une souris et plus tard rend la pareille lorsque le lion est capturé par des chasseurs.\n",
            "3 - lion, souris, chasseurs.\n",
            "4 - {\n",
            "    \"french_summary\": \"Un lion est sauvé par une souris et plus tard rend la pareille lorsque le lion est capturé par des chasseurs.\",\n",
            "    \"num_names\": 3\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask for output in a specified format"
      ],
      "metadata": {
        "id": "Yi7KXiQhFKci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2 = f\"\"\"\n",
        "Your task is to perform the following actions:\n",
        "1 - Summarize the following text delimited by\n",
        "  <> with 1 sentence.\n",
        "2 - Translate the summary into French.\n",
        "3 - List each name in the French summary.\n",
        "4 - Output a json object that contains the\n",
        "  following keys: french_summary, num_names.\n",
        "\n",
        "Use the following format:\n",
        "Text: <text to summarize>\n",
        "Summary: <summary>\n",
        "Translation: <summary translation>\n",
        "Names: <list of names in summary>\n",
        "Output JSON: <json with summary and num_names>\n",
        "\n",
        "Text: <{text}>\n",
        "\"\"\"\n",
        "response = get_completion(prompt_2)\n",
        "print(\"\\nCompletion for prompt 2:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYYAf2aGEGxH",
        "outputId": "cdd4b2b1-fe6f-437b-f00c-1decee5d775b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Completion for prompt 2:\n",
            "Summary: A lion and a mouse form an unlikely friendship when the mouse saves the lion's life, and later returns the favor when the lion is captured by hunters.\n",
            "Translation: Un lion et une souris se lient d'amitié improbable lorsque la souris sauve la vie du lion, et plus tard rend la pareille lorsque le lion est capturé par des chasseurs.\n",
            "Names: lion, mouse, hunters\n",
            "Output JSON: {\"french_summary\": \"Un lion et une souris se lient d'amitié improbable lorsque la souris sauve la vie du lion, et plus tard rend la pareille lorsque le lion est capturé par des chasseurs.\", \"num_names\": 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion"
      ],
      "metadata": {
        "id": "4YLqix9KHH4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STUDENT's calculation is in incorrect\n",
        "#Expected outcome is 360x + 100,000\n",
        "prompt = f\"\"\"\n",
        "Determine if the student's solution is correct or not.\n",
        "\n",
        "Question:\n",
        "I'm building a solar power installation and I need \\\n",
        " help working out the financials.\n",
        "- Land costs $100 / square foot\n",
        "- I can buy solar panels for $250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost \\\n",
        "me a flat $100k per year, and an additional $10 / square \\\n",
        "foot\n",
        "What is the total cost for the first year of operations\n",
        "as a function of the number of square feet.\n",
        "\n",
        "Student's Solution:\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15-pJ-uEFd1C",
        "outputId": "9cd89728-5123-46c8-e921-45d7f0983543"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The student's solution is correct. They correctly identified the costs for land, solar panels, and maintenance, and calculated the total cost as a function of the number of square feet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the student's solution is actually not correct.\n",
        "\n",
        "We can fix this by instructing the model to work out its own solution first."
      ],
      "metadata": {
        "id": "sQyEHghfH1cR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to determine if the student's solution \\\n",
        "is correct or not.\n",
        "To solve the problem do the following:\n",
        "- First, work out your own solution to the problem including the final total.\n",
        "- Then compare your solution to the student's solution \\\n",
        "and evaluate if the student's solution is correct or not.\n",
        "Don't decide if the student's solution is correct until\n",
        "you have done the problem yourself.\n",
        "\n",
        "Use the following format:\n",
        "Question:\n",
        "```\n",
        "question here\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "student's solution here\n",
        "```\n",
        "Actual solution:\n",
        "```\n",
        "steps to work out the solution and your solution here\n",
        "```\n",
        "Is the student's solution the same as actual solution \\\n",
        "just calculated:\n",
        "```\n",
        "yes or no\n",
        "```\n",
        "Student grade:\n",
        "```\n",
        "correct or incorrect\n",
        "```\n",
        "\n",
        "Question:\n",
        "```\n",
        "I'm building a solar power installation and I need help \\\n",
        "working out the financials.\n",
        "- Land costs $100 / square foot\n",
        "- I can buy solar panels for $250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost \\\n",
        "me a flat $100k per year, and an additional $10 / square \\\n",
        "foot\n",
        "What is the total cost for the first year of operations \\\n",
        "as a function of the number of square feet.\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "```\n",
        "Actual solution:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdLCQiZxHwRb",
        "outputId": "773f81d6-bfbe-4213-8d29-3079fa543242"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To calculate the total cost for the first year of operations, we need to add up the costs of land, solar panels, and maintenance.\n",
            "\n",
            "1. Land cost: $100 / square foot\n",
            "The cost of land is $100 multiplied by the size of the installation in square feet.\n",
            "\n",
            "2. Solar panel cost: $250 / square foot\n",
            "The cost of solar panels is $250 multiplied by the size of the installation in square feet.\n",
            "\n",
            "3. Maintenance cost: $100,000 + $10 / square foot\n",
            "The maintenance cost is a flat fee of $100,000 per year, plus $10 multiplied by the size of the installation in square feet.\n",
            "\n",
            "Total cost: Land cost + Solar panel cost + Maintenance cost\n",
            "\n",
            "Let's calculate the total cost using the actual solution:\n",
            "\n",
            "Total cost = (100 * x) + (250 * x) + (100,000 + (10 * x))\n",
            "           = 100x + 250x + 100,000 + 10x\n",
            "           = 360x + 100,000\n",
            "\n",
            "Is the student's solution the same as the actual solution just calculated:\n",
            "No\n",
            "\n",
            "Student grade:\n",
            "Incorrect\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Limitations: Hallucinations**\n",
        "\n",
        "\n",
        "*   Boie is a real company, the product name is not real\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QNDynPB_IlzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me about android xLED TV by visionTVs\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYoA3g4lH6Fy",
        "outputId": "74ea9c84-4998-4f90-cb9a-45a5f0207717"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The android xLED TV by visionTVs is a smart television that runs on the Android operating system. It is equipped with an xLED display technology, which stands for Extended Light Emitting Diode. This technology enhances the brightness and contrast levels of the TV, resulting in a more vibrant and immersive viewing experience.\n",
            "\n",
            "The android xLED TV comes in various screen sizes, ranging from small to large, catering to different preferences and room sizes. It offers a high-definition resolution, ensuring sharp and detailed visuals. Additionally, the TV supports HDR (High Dynamic Range) content, which further enhances the color accuracy and contrast ratio.\n",
            "\n",
            "As an Android TV, it provides access to a wide range of apps and streaming services through the Google Play Store. Users can download and install their favorite apps, such as Netflix, YouTube, Hulu, and more, directly on the TV. The android xLED TV also supports voice control, allowing users to search for content or control the TV using voice commands.\n",
            "\n",
            "Connectivity options include multiple HDMI ports, USB ports, and Wi-Fi, enabling users to connect external devices like gaming consoles, Blu-ray players, or USB drives. The TV also supports screen mirroring, allowing users to mirror their smartphone or tablet screens onto the TV for a larger display.\n",
            "\n",
            "Overall, the android xLED TV by visionTVs offers a combination of advanced display technology, smart features, and connectivity options, providing an immersive and convenient entertainment experience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Notes on using the OpenAI API outside of this classroom\n",
        "\n",
        "To install the OpenAI Python library:\n",
        "```\n",
        "!pip install openai\n",
        "```\n",
        "\n",
        "The library needs to be configured with your account's secret key, which is available on the [website](https://platform.openai.com/account/api-keys).\n",
        "\n",
        "You can either set it as the `OPENAI_API_KEY` environment variable before using the library:\n",
        " ```\n",
        " !export OPENAI_API_KEY='sk-...'\n",
        " ```\n",
        "\n",
        "Or, set `openai.api_key` to its value:\n",
        "\n",
        "```\n",
        "import openai\n",
        "openai.api_key = \"sk-...\"\n",
        "```"
      ],
      "metadata": {
        "id": "EL_2sTAAMaEa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A note about the backslash\n",
        "- In the course, we are using a backslash `\\` to make the text fit on the screen without inserting newline '\\n' characters.\n",
        "- GPT-3 isn't really affected whether you insert newline characters or not.  But when working with LLMs in general, you may consider whether newline characters in your prompt may affect the model's performance."
      ],
      "metadata": {
        "id": "F8rXZ2CGMc6m"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HGlvYgXWJKFi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}