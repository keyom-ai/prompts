{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keyom-ai/prompts/blob/main/guidelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guidelines for Prompting\n",
        "In this lesson, you'll practice two prompting principles and their related tactics in order to write effective prompts for large language models.\n",
        "\n",
        "## Setup\n",
        "#### Load the API key and relevant Python libaries."
      ],
      "metadata": {
        "id": "QO7CG_BJrH4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this course, we've provided some code that loads the OpenAI API key for you."
      ],
      "metadata": {
        "id": "Xj6ObRuMrQDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlKc97y4q_0N",
        "outputId": "7346911d-f407-4b19-98ac-47a139533106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "pip install openai==0.28"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the below cell, please insert your own API keys as value for `openai.api_key` variable. You can create your own API keys at (https://platform.openai.com/api-keys)"
      ],
      "metadata": {
        "id": "asupmJ7pI5LK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = 'sk-abcdefghijklmnopqrstuvwxyz0123456789'"
      ],
      "metadata": {
        "id": "Gtok-cNrrdwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prompting Principles\n",
        "\n",
        "*   Principle 1: Write clear and specific instructions\n",
        "*   Principle 2: Give the model time to “think”\n",
        "\n",
        "\n",
        "##Tactics\n",
        "###Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
        "\n",
        "*   Delimiters can be anything like: ```, \"\"\", < >, <tag> </tag>, :\n",
        "\n"
      ],
      "metadata": {
        "id": "fnylhNGnr1xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "You should express what you want a model to do by\n",
        "providing instructions that are as clear and\n",
        "specific as you can possibly make them.\n",
        "This will guide the model towards the desired output,\n",
        "and reduce the chances of receiving irrelevant\n",
        "or incorrect responses. Don't confuse writing a\n",
        "clear prompt with writing a short prompt.\n",
        "In many cases, longer prompts provide more clarity\n",
        "and context for the model, which can lead to\n",
        "more detailed and relevant outputs.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by triple backticks\n",
        "into a single sentence.\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtdFGSPxriZ9",
        "outputId": "08ba4bfb-500d-4a75-ff33-d338f41f1bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
            "  \"id\": \"cmpl-8O66I2DO6p1qqGiYOgpJoEJ7f7tny\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1700754014,\n",
            "  \"model\": \"text-davinci-002\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"\\nIt is important to be clear and specific when writing instructions for a model, as this will help the model produce the desired output.\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 122,\n",
            "    \"completion_tokens\": 27,\n",
            "    \"total_tokens\": 149\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tactic 2: Ask for a structured output\n",
        "- JSON, HTML"
      ],
      "metadata": {
        "id": "URNg_DlPuVz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Generate a list of three film titles along \\\n",
        "with their directors and genres.\n",
        "Provide them in JSON format with the following keys:\n",
        "film_id, title, director, genre.\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-nXI1rxsb8E",
        "outputId": "f19ac4f7-6a80-4a7e-e5c4-50af5e067d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
            "  \"id\": \"cmpl-8O5sgoVWUfyBcEqrjuvEz9eBPDhq8\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1700753170,\n",
            "  \"model\": \"text-davinci-002\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"\\n{\\n\\t\\\"film_id\\\": 1,\\n\\t\\\"title\\\": \\\"The Shawshank Redemption\\\",\\n\\t\\\"director\\\": \\\"Frank Darabont\\\",\\n\\t\\\"genre\\\": \\\"Drama\\\"\\n},\\n{\\n\\t\\\"film_id\\\": 2,\\n\\t\\\"title\\\": \\\"The God\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"length\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 45,\n",
            "    \"completion_tokens\": 64,\n",
            "    \"total_tokens\": 109\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tactic 3: Ask the model to check whether conditions are satisfied"
      ],
      "metadata": {
        "id": "-Z5h1vpzu0_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = f\"\"\"\n",
        "Making a cup of tea is easy! First, you need to get some\n",
        "water boiling. While that's happening,\n",
        "grab a cup and put a tea bag in it. Once the water is\n",
        "hot enough, just pour it over the tea bag.\n",
        "Let it sit for a bit so the tea can steep. After a\n",
        "few minutes, take out the tea bag. If you\n",
        "like, you can add some sugar or milk to taste.\n",
        "And that's it! You've got yourself a delicious\n",
        "cup of tea to enjoy.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions,\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions,\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "print(\"Completion for Text 1:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5fZ6_KftDkT",
        "outputId": "a7e4571a-ed49-427f-a1a0-374ced7d8d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 1:\n",
            "{\n",
            "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
            "  \"id\": \"cmpl-8O5tRxDALuWeB6zvz8a3cKwbZhihN\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1700753217,\n",
            "  \"model\": \"text-davinci-002\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"\\nStep 1 - Get some water boiling\\nStep 2 - Grab a cup and put a tea bag in it\\nStep 3 - Once the water is hot enough, just pour it over the tea bag\\nStep 4 - Let it sit for a bit so the tea can steep\\nStep 5 - After a few minutes,\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"length\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 192,\n",
            "    \"completion_tokens\": 64,\n",
            "    \"total_tokens\": 256\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = f\"\"\"\n",
        "The sun is shining brightly today, and the birds are singing happily.\n",
        "It's perfect for taking a walk in the park.\n",
        "The flowers look really pretty, and the trees are moving in the breeze.\n",
        "Lots of people are outside, enjoying the nice weather.\n",
        "Some are having picnics, others are playing games,\n",
        "and some are just sitting on the grass and relaxing.\n",
        "It's a great day to be outdoors and enjoy the beauty of nature.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, \\\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions, \\\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "print(\"Completion for Text 2:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoK6ktz_u8pp",
        "outputId": "23d54458-fca5-447c-d28e-f1a723a16c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 2:\n",
            "{\n",
            "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
            "  \"id\": \"cmpl-8O5w8MSXqdWkipBIJ2MoNFIeFkmeR\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1700753384,\n",
            "  \"model\": \"text-davinci-002\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"\\nNo steps provided.\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 181,\n",
            "    \"completion_tokens\": 5,\n",
            "    \"total_tokens\": 186\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tactic 4: \"Few-shot\" prompting"
      ],
      "metadata": {
        "id": "w6GqAP7AwEwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to answer in a consistent style.\n",
        "\n",
        "<child>: Teach me about patience.\n",
        "\n",
        "<grandparent>: The river that carves the largest\n",
        "valley flows from a small spring\n",
        "the grandest symphony originates from a single note\n",
        "the most intricate tapestry begins with a solitary thread.\n",
        "\n",
        "<child>: Teach me about strength.\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9CSGEqWv5FB",
        "outputId": "15394c4a-6b9b-486d-da36-a4b1fa173901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
            "  \"id\": \"cmpl-8O5xTrEIA5twreI2oJblLLmbjCiRJ\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1700753467,\n",
            "  \"model\": \"text-davinci-002\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"\\n<grandparent>: The strongest steel is forged in the hottest fire\\nthe most resilient tree grows in the harshest conditions\\nthe hardest rock is found at the bottom of the ocean.\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 78,\n",
            "    \"completion_tokens\": 38,\n",
            "    \"total_tokens\": 116\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Principle 2: Give the model time to “think”\n",
        "\n",
        "### Tactic 1: Specify the steps required to complete a task"
      ],
      "metadata": {
        "id": "FWVOiVf7wftF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "In a delightful village, brother Jack and sister Jill\n",
        "embarked on a journey to fetch water from a well atop a hill.\n",
        "While climbing and singing happily, an unfortunate event\n",
        "occurred—Jack stumbled on a stone, and both of them tumbled\n",
        "down the hill, a bit bruised but still in good spirits.\n",
        "Upon their return home, they were greeted with comforting hugs.\n",
        "Despite the little accident, their adventurous enthusiasm stayed strong,\n",
        "and they continued to explore with joy.\n",
        "\"\"\"\n",
        "# example 1\n",
        "prompt_1 = f\"\"\"\n",
        "Perform the following actions:\n",
        "1 - Summarize the following text delimited by triple\n",
        "backticks with 1 sentence.\n",
        "2 - List each name in the summary.\n",
        "3 - Translate the summary into French.\n",
        "4 - Output a json object that contains the following\n",
        "keys: summary, num_names.\n",
        "\n",
        "Separate your answers with line breaks.\n",
        "\n",
        "Text:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt_1,\n",
        "  temperature=0.4,\n",
        "  max_tokens=264\n",
        ")\n",
        "print(\"Completion for prompt 1:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfKqd1CrwN88",
        "outputId": "67999d55-f87a-403a-fac5-c84bd4f45bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for prompt 1:\n",
            "{\n",
            "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
            "  \"id\": \"cmpl-8O60Q5punhDz9Xm32UMWQqq7KejQb\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1700753650,\n",
            "  \"model\": \"text-davinci-002\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"\\n1 - Jack and Jill go on an adventure to get water, but they fall down and get hurt.\\n2 - Jack, Jill, stone.\\n3 - Dans un charmant village, le fr\\u00e8re Jack et la soeur Jill ont entrepris un voyage pour aller chercher de l'eau au sommet d'une colline. Alors qu'ils grimpent et chantent joyeusement, un malheureux \\u00e9v\\u00e9nement s'est produit: Jack a tr\\u00e9buch\\u00e9 sur une pierre et ils ont tous les deux roul\\u00e9 en bas de la colline, un peu meurtris mais toujours de bonne humeur. \\u00c0 leur retour \\u00e0 la maison, ils ont \\u00e9t\\u00e9 accueillis par des c\\u00e2lins r\\u00e9confortants. Malgr\\u00e9 l'accident, leur enthousiasme pour l'aventure \\u00e9tait toujours aussi fort et ils ont continu\\u00e9 \\u00e0 explorer avec joie.\\n4 - {\\\"summary\\\": \\\"Jack and Jill go on an adventure to get water, but they fall down and get hurt.\\\", \\\"num_names\\\": 3}\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 199,\n",
            "    \"completion_tokens\": 263,\n",
            "    \"total_tokens\": 462\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ask for output in a specified format"
      ],
      "metadata": {
        "id": "yKa3q8WbxABu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2 = f\"\"\"\n",
        "Your task is to perform the following actions:\n",
        "1 - Summarize the following text delimited by\n",
        "  <> with 1 sentence.\n",
        "2 - Translate the summary into French.\n",
        "3 - List each name in the French summary.\n",
        "4 - Output a json object that contains the\n",
        "  following keys: french_summary, num_names.\n",
        "\n",
        "Use the following format:\n",
        "Text: <text to summarize>\n",
        "Summary: <summary>\n",
        "Translation: <summary translation>\n",
        "Names: <list of names in summary>\n",
        "Output JSON: <json with summary and num_names>\n",
        "\n",
        "Text: <{text}>\n",
        "\"\"\"\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt_2,\n",
        "  temperature=0.4,\n",
        "  max_tokens=264\n",
        ")\n",
        "print(\"\\nCompletion for prompt 2:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vII_-TalwxdL",
        "outputId": "9989c491-8766-4f49-a761-30ad229f9ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Completion for prompt 2:\n",
            "{\n",
            "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
            "  \"id\": \"cmpl-8O5n4HwrX9NtjzOIAB9BFkgdhwgDg\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1700752822,\n",
            "  \"model\": \"text-davinci-002\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"Summary: Jack and Jill go on a quest to fetch water, but they fall down and get hurt. They go home and get comforted, and they continue exploring with delight.\\nTranslation: Dans un charmant village, les fr\\u00e8res et soeurs Jack et Jill entreprennent un voyage pour aller chercher de l'eau d'un puits en haut d'une colline. Alors qu'ils grimpent, chantant joyeusement, le malheur frappe-Jack tr\\u00e9buche sur une pierre et roule en bas de la colline, avec Jill qui le suit. Bien que l\\u00e9g\\u00e8rement amoch\\u00e9s, le duo rentre \\u00e0 la maison pour se r\\u00e9conforter dans les bras l'un de l'autre. Malgr\\u00e9 le contretemps, leur esprit aventurier demeure intact et ils continuent d'explorer avec joie.\\nNames: Jack, Jill, their\\nOutput JSON: {\\n  \\\"french_summary\\\": \\\"Dans un charmant village, les fr\\u00e8res et soeurs Jack et Jill entreprennent un voyage pour aller chercher\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"length\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 248,\n",
            "    \"completion_tokens\": 264,\n",
            "    \"total_tokens\": 512\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion"
      ],
      "metadata": {
        "id": "Q34reFDrw_Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Determine if the student's solution is correct or not.\n",
        "\n",
        "Question:\n",
        "I'm building a solar power installation and I need \\\n",
        " help working out the financials.\n",
        "- Land costs $100 / square foot\n",
        "- I can buy solar panels for $250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost \\\n",
        "me a flat $100k per year, and an additional $10 / square \\\n",
        "foot\n",
        "What is the total cost for the first year of operations\n",
        "as a function of the number of square feet.\n",
        "\n",
        "Student's Solution:\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "\"\"\"\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=264\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFqGLiHPxOot",
        "outputId": "ea40a799-ba6b-4132-a34c-794708f8c32e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
            "  \"id\": \"cmpl-8O620MCpdOau7nIUJHV8w9L4CVS6u\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1700753748,\n",
            "  \"model\": \"text-davinci-002\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"\\nThe student's solution is correct.\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 191,\n",
            "    \"completion_tokens\": 8,\n",
            "    \"total_tokens\": 199\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Note that the student's solution is actually not correct.\n",
        "#### We can fix this by instructing the model to work out its own solution first."
      ],
      "metadata": {
        "id": "DdlvYdzcxkze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to determine if the student's solution \\\n",
        "is correct or not.\n",
        "To solve the problem do the following:\n",
        "- First, work out your own solution to the problem including the final total.\n",
        "- Then compare your solution to the student's solution \\\n",
        "and evaluate if the student's solution is correct or not.\n",
        "Don't decide if the student's solution is correct until\n",
        "you have done the problem yourself.\n",
        "\n",
        "Use the following format:\n",
        "Question:\n",
        "```\n",
        "question here\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "student's solution here\n",
        "```\n",
        "Actual solution:\n",
        "```\n",
        "steps to work out the solution and your solution here\n",
        "```\n",
        "Is the student's solution the same as actual solution \\\n",
        "just calculated:\n",
        "```\n",
        "yes or no\n",
        "```\n",
        "Student grade:\n",
        "```\n",
        "correct or incorrect\n",
        "```\n",
        "\n",
        "Question:\n",
        "```\n",
        "I'm building a solar power installation and I need help \\\n",
        "working out the financials.\n",
        "- Land costs $100 / square foot\n",
        "- I can buy solar panels for $250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost \\\n",
        "me a flat $100k per year, and an additional $10 / square \\\n",
        "foot\n",
        "What is the total cost for the first year of operations \\\n",
        "as a function of the number of square feet.\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "```\n",
        "Actual solution:\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=564\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Kte4iopxWjP",
        "outputId": "3362602f-edba-4ba5-9550-78980a456025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
            "  \"id\": \"cmpl-8O62k3C958OyH5OjyauyxJQm2sCRY\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1700753794,\n",
            "  \"model\": \"text-davinci-002\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"```\\nLet x be the size of the installation in square feet.\\nCosts:\\n1. Land cost: 100x\\n2. Solar panel cost: 250x\\n3. Maintenance cost: 100,000 + 100x\\nTotal cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\\n```\\nIs the student's solution the same as actual solution just calculated:\\n```\\nyes\\n```\\nStudent grade:\\n```\\ncorrect\\n```\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 374,\n",
            "    \"completion_tokens\": 108,\n",
            "    \"total_tokens\": 482\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Limitations: Hallucinations\n",
        "- Boie is a real company, the product name is not real."
      ],
      "metadata": {
        "id": "OpiBaP7Xx2be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me about Beardica Smart Beard multipurpose Trimmer by Braig\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=564\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1a-7LBYxqeu",
        "outputId": "05bb8732-01f9-42be-e372-85622c7df48b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
            "  \"id\": \"cmpl-8O64sfng0GjlAWJcNv9X7ZULLLLmQ\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1700753926,\n",
            "  \"model\": \"text-davinci-002\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"\\nBeardica Smart Beard multipurpose Trimmer by Braig is a versatile trimmer that can be used for a variety of purposes, including trimming beards, mustaches, and other facial hair. It features a detachable head that can be used for different purposes, and it also comes with a storage case.\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 17,\n",
            "    \"completion_tokens\": 66,\n",
            "    \"total_tokens\": 83\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Notes on using the OpenAI API outside of this classroom\n",
        "\n",
        "To install the OpenAI Python library:\n",
        "```\n",
        "!pip install openai\n",
        "```\n",
        "\n",
        "The library needs to be configured with your account's secret key, which is available on the [website](https://platform.openai.com/account/api-keys).\n",
        "\n",
        "You can either set it as the `OPENAI_API_KEY` environment variable before using the library:\n",
        " ```\n",
        " !export OPENAI_API_KEY='sk-...'\n",
        " ```\n",
        "\n",
        "Or, set `openai.api_key` to its value:\n",
        "\n",
        "```\n",
        "import openai\n",
        "openai.api_key = \"sk-...\"\n",
        "```"
      ],
      "metadata": {
        "id": "RiklVBXmyCTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A note about the backslash\n",
        "- In the course, we are using a backslash `\\` to make the text fit on the screen without inserting newline '\\n' characters.\n",
        "- GPT-3 isn't really affected whether you insert newline characters or not.  But when working with LLMs in general, you may consider whether newline characters in your prompt may affect the model's performance."
      ],
      "metadata": {
        "id": "ooc-YbetyNAf"
      }
    }
  ]
}