{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keyom-ai/prompts/blob/main/inferring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inferring\n",
        "In this lesson, you will infer sentiment and topics from product reviews and news articles."
      ],
      "metadata": {
        "id": "JBKuW_NDXaAO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kStqtHneaHC2",
        "outputId": "966acaf5-470d-49a9-93f9-6f7d8447fe37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "pip install openai==0.28"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "In the below cell, please insert your own API keys as value for `openai.api_key` variable. You can create your own API keys at (https://platform.openai.com/api-keys)"
      ],
      "metadata": {
        "id": "PT8AH8lfawTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = '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'"
      ],
      "metadata": {
        "id": "bAs2y_WMaOdO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Product review text"
      ],
      "metadata": {
        "id": "tgH6hBaxa0d6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fan_review = \"\"\"\n",
        "\n",
        "Recently, I was in search of a smart fan for my living room, and after\n",
        "some research, I stumbled upon this gem. The additional features it\n",
        "offered were exactly what I needed, and the price point was quite reasonable.\n",
        "The delivery was prompt, and I was eager to set it up.\n",
        "However, during transit, there was a minor hiccup – the remote control seemed\n",
        "to be malfunctioning. I reached out to customer support, and to my pleasant\n",
        "surprise, they swiftly dispatched a replacement remote. It arrived\n",
        "within a few days, and I was back in business.\n",
        "Putting the fan together was a breeze, and the instructions were clear. But,\n",
        "as luck would have it, I discovered a missing part. Not to worry, though – a\n",
        "quick call to their support team, and they promptly shipped the missing piece.\n",
        "The dedication of the support team left a positive impression on me.\n",
        "This smart fan is not just a functional addition to my home; it's a testament\n",
        "to the commitment of the company behind it. Kudos to the team at the company\n",
        " for their exceptional customer service and top-notch product!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fQNEBFGfajKR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment (positive/negative)"
      ],
      "metadata": {
        "id": "gU4y0jLBa60p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review,\n",
        "which is delimited with triple backticks?\n",
        "\n",
        "Review text: '''{fan_review}'''\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9m8nKlya4Qp",
        "outputId": "75d54dab-0202-471a-a5d0-abf802041aaa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The sentiment of this product review is positive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review,\n",
        "which is delimited with triple backticks?\n",
        "\n",
        "Give your answer as a single word, either \"positive\" \\\n",
        "or \"negative\".\n",
        "\n",
        "Review text: '''{fan_review}'''\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E17LFwcRbADu",
        "outputId": "86d7bcf0-937b-452c-c94c-c50ad9a5915a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify types of emotions"
      ],
      "metadata": {
        "id": "LeJC5zVbbH7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Identify a list of emotions that the writer of the \\\n",
        "following review is expressing. Include no more than \\\n",
        "five items in the list. Format your answer as a list of \\\n",
        "lower-case words separated by commas.\n",
        "\n",
        "Review text: '''{fan_review}'''\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmxIO2ovbE4d",
        "outputId": "e4ce30e5-e727-4cfa-baef-662e9a2e7ced"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "pleased, satisfied, happy, content, proud\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify anger"
      ],
      "metadata": {
        "id": "glNYGJTzbOhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Is the writer of the following review expressing anger?\\\n",
        "The review is delimited with triple backticks. \\\n",
        "Give your answer as either yes or no.\n",
        "\n",
        "Review text: '''{fan_review}'''\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfrnbFpbbL2k",
        "outputId": "72e8e337-cb1a-4554-9c41-ad356e82089a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract product and company name from customer reviews"
      ],
      "metadata": {
        "id": "h4ODOKhZbcZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text:\n",
        "- Item purchased by reviewer\n",
        "- Company that made the item\n",
        "\n",
        "The review is delimited with triple backticks. \\\n",
        "Format your response as a JSON object with \\\n",
        "\"Item\" and \"Brand\" as the keys.\n",
        "If the information isn't present, use \"unknown\" \\\n",
        "as the value.\n",
        "Make your response as short as possible.\n",
        "\n",
        "Review text: '''{fan_review}'''\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVanSCk_bUB8",
        "outputId": "1dd298ab-0ca0-4d9f-c830-7226a9c116d5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "{\n",
            "    \"Item\": \"smart fan\",\n",
            "    \"Brand\": \"the company\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Doing multiple tasks at once"
      ],
      "metadata": {
        "id": "bFybQkaucQYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text:\n",
        "- Sentiment (positive or negative)\n",
        "- Is the reviewer expressing anger? (true or false)\n",
        "- Item purchased by reviewer\n",
        "- Company that made the item\n",
        "\n",
        "The review is delimited with triple backticks. \\\n",
        "Format your response as a JSON object with \\\n",
        "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
        "If the information isn't present, use \"unknown\" \\\n",
        "as the value.\n",
        "Make your response as short as possible.\n",
        "Format the Anger value as a boolean.\n",
        "\n",
        "Review text: '''{fan_review}'''\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z9SZsnQbhsE",
        "outputId": "5df7d1fb-2937-49c8-aa0d-adbec5efbebd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "{\n",
            "    \"Sentiment\": \"positive\",\n",
            "    \"Anger\": false,\n",
            "    \"Item\": \"smart fan\",\n",
            "    \"Brand\": \"the company\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inferring topics"
      ],
      "metadata": {
        "id": "iWhpEdbRcT7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "story = \"\"\"\n",
        "In a recent nationwide survey gauging the job satisfaction of public sector\n",
        "employees, NASA emerged as the shining star with an impressive satisfaction\n",
        "rating of 95%. The findings reflect the sentiments of dedicated professionals\n",
        "within the space agency, highlighting a positive work environment and a sense\n",
        "of pride in contributing to groundbreaking endeavors.\n",
        "Among those who expressed their contentment was John Smith, a proud NASA\n",
        "employee, who remarked, \"It's no surprise to me that NASA is at the top.\n",
        "This is a fantastic workplace with brilliant minds and unparalleled\n",
        "opportunities. I'm genuinely honored to be a part of such an innovative\n",
        "and forward-thinking organization.\"\n",
        "NASA's management, led by Director Tom Johnson, welcomed the survey results\n",
        "with enthusiasm. Johnson stated, \"We are thrilled to learn that our employees\n",
        "find fulfillment in their work at NASA. Our team consists of exceptionally\n",
        "talented and committed individuals who tirelessly strive to achieve our\n",
        "ambitious goals. It's truly gratifying to see that their dedication is\n",
        "reflected in this high satisfaction rating.\"\n",
        "However, the survey also shed light on the challenges faced by other\n",
        "government departments, with the Social Security Administration receiving\n",
        "the lowest satisfaction rating at 45%. In response, the government has\n",
        "pledged to address the concerns raised by employees across all departments,\n",
        "aiming to enhance job satisfaction and cultivate positive work environments\n",
        "nationwide. The results underscore the importance of continuous improvement\n",
        "and support for those who contribute to the nation's diverse array\n",
        "of public services.\"\"\""
      ],
      "metadata": {
        "id": "H2uee72zbpov"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Infer 5 topics"
      ],
      "metadata": {
        "id": "JcVbHJVCcZ0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Determine five topics that are being discussed in the \\\n",
        "following text, which is delimited by triple backticks.\n",
        "\n",
        "Make each item one or two words long.\n",
        "\n",
        "Format your response as a list of items separated by commas.\n",
        "\n",
        "Text sample: '''{story}'''\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMMoYV2Sbs-Z",
        "outputId": "4ddaf242-8ef1-4d74-9bba-d5184e4689d9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NASA, job satisfaction, public sector employees, the Social Security Administration, government departments, positive work environments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_list = [\n",
        "    \"nasa\", \"local government\", \"engineering\",\n",
        "    \"employee satisfaction\", \"federal government\"\n",
        "]"
      ],
      "metadata": {
        "id": "CiJ2-dHTbzsA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a news alert for certain topics"
      ],
      "metadata": {
        "id": "i-guJN8BceQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Determine whether each item in the following list of \\\n",
        "topics is a topic in the text below, which\n",
        "is delimited with triple backticks.\n",
        "\n",
        "Give your answer as list with 0 or 1 for each topic.\\\n",
        "\n",
        "List of topics: {\", \".join(topic_list)}\n",
        "\n",
        "Text sample: '''{story}'''\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNDJ4nxyb3O5",
        "outputId": "554b8f81-f841-491e-921c-7f330f23b083"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    }
  ]
}