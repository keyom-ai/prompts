{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keyom-ai/prompts/blob/main/transforming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3993515-9710-4ac4-89e9-b35ebb81e920",
      "metadata": {
        "id": "e3993515-9710-4ac4-89e9-b35ebb81e920"
      },
      "source": [
        "# Transforming\n",
        "\n",
        "In this notebook, we will explore how to use Large Language Models for text transformation tasks such as language translation, spelling and grammar checking, tone adjustment, and format conversion.\n",
        "\n",
        "## Setup",
        "\n",
        "In the below cell, please insert your own API keys as value for `openai.api_key` variable. You can create your own API keys at (https://platform.openai.com/api-keys)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GSr5VGaZ8yt",
        "outputId": "8881d625-60e0-44be-b910-9790effe0fc6"
      },
      "id": "7GSr5VGaZ8yt",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "41df0348",
      "metadata": {
        "tags": [],
        "id": "41df0348"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "openai.api_key  = 'sk-abcdefghijklmnopqrstuvwxyz0123456789'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d8f0bd8-628e-4c36-bcd0-2110162f25fc",
      "metadata": {
        "id": "1d8f0bd8-628e-4c36-bcd0-2110162f25fc"
      },
      "source": [
        "## Translation\n",
        "\n",
        "ChatGPT is trained with sources in many languages. This gives the model the ability to do translation. Here are some examples of how to use this capability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "9c4df6ff",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c4df6ff",
        "outputId": "04bc7029-bbc1-4db3-eaaf-62b02b0ecf1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "```Hola, me gustaría pedir una mesa de comedor?```\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following English text to Spanish: \\\n",
        "```Hi, I would like to order a dining table?```\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "print(response['choices'][0]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "7300ed9b",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7300ed9b",
        "outputId": "7c709249-a210-4682-93ee-fe73e38f5a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "This is French.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me which language this is:\n",
        "```Je m'appelle Sean. J'ai 16```\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "print(response['choices'][0]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "791e789b",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "791e789b",
        "outputId": "04397f0e-a2fc-499a-bc37-d31c257f6c31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Je veux manger une pizza pour le déjeuner aujourd'hui.\n",
            "\n",
            "Quiero comer pizza para el almuerzo hoy.\n",
            "\n",
            "I want to eat a pizza for lunch today.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following  text to French and Spanish\n",
        "and English pirate: \\\n",
        "```I want to eat pizza for lunch today```\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "print(response['choices'][0]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "fcf7eb63",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcf7eb63",
        "outputId": "fd55db79-2d03-413d-9cf9-7d3bd7817520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "¿Quieres pedir una hamburguesa hoy?\n",
            "¿Te gustaría pedir una hamburguesa hoy?\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following text to Spanish in both the formal and informal forms:\n",
        "'Would you like to order a burger today?'\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "print(response['choices'][0]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8edb56d2-a32a-470f-9f40-4fc5b1ea0849",
      "metadata": {
        "id": "8edb56d2-a32a-470f-9f40-4fc5b1ea0849"
      },
      "source": [
        "### Universal Translator\n",
        "Imagine you are in charge of IT at a large multinational e-commerce company. Users are messaging you with IT issues in all their native languages. Your staff is from all over the world and speaks only their native languages. You need a universal translator!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "68a40bf0",
      "metadata": {
        "tags": [],
        "id": "68a40bf0"
      },
      "outputs": [],
      "source": [
        "user_messages = [\n",
        "  \"La performance du système est plus lente que d'habitude.\",\n",
        "  # System performance is slower than normal\n",
        "  \"Mi monitor tiene píxeles que no se iluminan.\",\n",
        "  # My monitor has pixels that are not lighting\n",
        "  \"Il mio mouse non funziona\",\n",
        "  # My mouse is not working\n",
        "  \"Mój klawisz Ctrl jest zepsuty\",\n",
        "  # My keyboard has a broken control key\n",
        "  \"我的屏幕在闪烁\"\n",
        "  # My screen is flashing\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "552d0db9",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "552d0db9",
        "outputId": "22eab78c-3eb9-4c80-fd47-341fdcc38177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "This is French.\n",
            "\n",
            "    The system performance is slower than usual.\n",
            "    \n",
            "    시스템 성능이 일반적보다 느립니다.\n",
            "\n",
            "\n",
            "This is Spanish.\n",
            "\n",
            "    ```My monitor has pixels that don't light up.```\n",
            "    \n",
            "    ```내 모니터에는 밝혀지지 않는 픽셀이 있습니다.```\n",
            "\n",
            "\n",
            "This is Italian.\n",
            "\n",
            "    My mouse is not working.\n",
            "\n",
            "    내 마우스가 작동하지 않습니다.\n",
            "\n",
            "\n",
            "This is Polish.\n",
            "\n",
            "    ```My Ctrl key is broken```\n",
            "    \n",
            "    ```내 컨트롤 키가 고장났어요```\n",
            "\n",
            "\n",
            "This is Mandarin Chinese.\n",
            "\n",
            "    My screen is flashing.\n",
            "    \n",
            "    제 스크린이 깜빡이고 있습니다.\n"
          ]
        }
      ],
      "source": [
        "for issue in user_messages:\n",
        "    prompt = f\"Tell me what language this is: ```{issue}```\"\n",
        "    lang = openai.Completion.create(\n",
        "      engine=\"text-davinci-002\",\n",
        "      prompt=prompt,\n",
        "      temperature=0.4,\n",
        "      max_tokens=64\n",
        "    )\n",
        "    print(lang['choices'][0]['text'])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Translate the following  text to English \\\n",
        "    and Korean: ```{issue}```\n",
        "    \"\"\"\n",
        "    response = openai.Completion.create(\n",
        "      engine=\"text-davinci-002\",\n",
        "      prompt=prompt,\n",
        "      temperature=0.4,\n",
        "      max_tokens=264\n",
        "    )\n",
        "    print(response['choices'][0]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d9e54ca-f93a-43c8-a295-bff7a89f77f5",
      "metadata": {
        "id": "1d9e54ca-f93a-43c8-a295-bff7a89f77f5"
      },
      "source": [
        "## Tone Transformation\n",
        "Writing can vary based on the intended audience. ChatGPT can produce different tones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "2deac328",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2deac328",
        "outputId": "697e09f8-59a5-4e36-fbbf-a42dee94dcee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dear Jason,\n",
            "\n",
            "Thank you for your interest in the latest PlayStation processor. We are excited to offer this new product to our customers and believe it will be a great addition to their gaming experience.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following from slang to a business letter:\n",
        "'Dude, This is Jason, check out the new processor on the latest play station.'\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=64\n",
        ")\n",
        "print(response['choices'][0]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2c7eb73-6b82-442d-b4f8-251c308e89d5",
      "metadata": {
        "id": "a2c7eb73-6b82-442d-b4f8-251c308e89d5"
      },
      "source": [
        "## Format Conversion\n",
        "ChatGPT can translate between formats. The prompt should describe the input and output formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "5a37f0a0",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a37f0a0",
        "outputId": "1d655d74-a8ed-46ec-feb6-7df1c897231b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<table>\n",
            "    <tr>\n",
            "        <th>Name</th>\n",
            "        <th>Email</th>\n",
            "    </tr>\n",
            "    <tr>\n",
            "        <td>Shubh</td>\n",
            "        <td>shubh26@gmail.com</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "        <td>Rohith</td>\n",
            "        <td>rohith69@gmail.com</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "        <td>Akash</td>\n",
            "        <td>akki78@gmail.com</td>\n",
            "    </tr>\n",
            "</table>\n"
          ]
        }
      ],
      "source": [
        "data_json = { \"resturant employees\" :[\n",
        "    {\"name\":\"Shubh\", \"email\":\"shubh26@gmail.com\"},\n",
        "    {\"name\":\"Rohith\", \"email\":\"rohith69@gmail.com\"},\n",
        "    {\"name\":\"Akash\", \"email\":\"akki78@gmail.com\"}\n",
        "]}\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Translate the following python dictionary from JSON to an HTML\n",
        "table with column headers and title: {data_json}\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=300\n",
        ")\n",
        "print(response['choices'][0]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df1824c-534b-45cb-b0c1-3000bba5adbe",
      "metadata": {
        "id": "2df1824c-534b-45cb-b0c1-3000bba5adbe"
      },
      "source": [
        "## Spellcheck/Grammar check.\n",
        "\n",
        "Here are some examples of common grammar and spelling problems and the LLM's response.\n",
        "\n",
        "To signal to the LLM that you want it to proofread your text, you instruct the model to 'proofread' or 'proofread and correct'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "52d77283",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52d77283",
        "outputId": "e52f3d7e-158b-4631-c841-b461328db44c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The man with the black puppies has a book.\n",
            "\n",
            "\n",
            "Priyal has her notebook.\n",
            "\n",
            "\n",
            "It's going to be a long day. Does the car need its oil changed?\n",
            "\n",
            "\n",
            "Their goes my freedom. There going to bring they’re backpacks.\n",
            "\n",
            "\n",
            "You're going to need your notebook.\n",
            "\n",
            "\n",
            "That medicine affects my sleep. Have you heard about the butterfly effect?\n",
            "\n",
            "\n",
            "This phrase is to check chatGPT for spelling ability.\n"
          ]
        }
      ],
      "source": [
        "text = [\n",
        "  \"The man with the black puppies have a book.\",  # The man has a book.\n",
        "  \"Priyal has her notebook.\", # ok\n",
        "  \"Its going to be a long day. Does the car need it’s oil changed?\",  # Homonyms\n",
        "  \"Their goes my freedom. There going to bring they’re backpacks.\",  # Homonyms\n",
        "  \"Your going to need you’re notebook.\",  # Homonyms\n",
        "  \"That medicine effects my sleep. Have you heard about the butterfly affect?\", # Homonyms\n",
        "  \"This phrase is to cherck chatGPT for spelang abilitty\"  # spelling\n",
        "]\n",
        "for t in text:\n",
        "    prompt = f\"\"\"Proofread and correct the following text\n",
        "    and rewrite the corrected version. If you don't find\n",
        "    and errors, just say \"No errors found\". Don't use\n",
        "    any punctuation around the text:\n",
        "    ```{t}```\"\"\"\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "      engine=\"text-davinci-002\",\n",
        "      prompt=prompt,\n",
        "      temperature=0.4,\n",
        "      max_tokens=564\n",
        "    )\n",
        "    print(response['choices'][0]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "7543fe7d",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7543fe7d",
        "outputId": "050c78eb-765d-41ee-abd5-fec65403e8bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "I purchased this for my daughter's birthday because she constantly borrows mine from my room. Pandas aren't just for kids; adults love them too. She carries it everywhere, and it's incredibly soft and adorable. However, I noticed a slight asymmetry in the ears, which I don't believe was intentional. Despite being a bit small for its price, there might be larger alternatives available for the same cost. Surprisingly, it arrived a day earlier than anticipated, allowing me to enjoy it before gifting it to my daughter.\n"
          ]
        }
      ],
      "source": [
        "text = f\"\"\"\n",
        "I purchased this for my daughter's birthday because she consistently\n",
        " borrows mine from my room. Pandas aren't just for kids; adults love\n",
        " them too. She carries it everywhere, and it's incredibly soft and adorable.\n",
        " However, I noticed a slight asymmetry in the ears, which I don't believe\n",
        " was intentional. Despite being a bit small for its price, there might be\n",
        " larger alternatives available for the same cost. Surprisingly, it\n",
        " arrived a day earlier than anticipated, allowing me to enjoy it before\n",
        " gifting it to my daughter.\n",
        "\"\"\"\n",
        "prompt = f\"proofread and correct this review: ```{text}```\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=564\n",
        ")\n",
        "print(response['choices'][0]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "2b4e73fd",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b4e73fd",
        "outputId": "1f3d1cf8-0f26-4a8e-d35a-40dab7928962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "I purchased this for my daughter's birthday because she loves pandas and borrows mine all the time. The panda is incredibly soft and adorable, but I noticed a slight asymmetry in the ears which may have been unintentional. Despite being a bit small for its price, there might be larger alternatives available for the same cost. Surprisingly, it arrived a day earlier than anticipated, allowing me to enjoy it before gifting it to my daughter.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "proofread and correct this review. Make it more compelling.\n",
        "Ensure it follows APA style guide and targets an advanced reader.\n",
        "Text: ```{text}```\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.4,\n",
        "  max_tokens=564\n",
        ")\n",
        "print(response['choices'][0]['text'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
